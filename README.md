# 3xod

Plateforme conversationnelle qui dÃ©niche des activitÃ©s inspirantes Ã  partir dâ€™une question libre. Le monorepo pnpm contient trois packages principauxÂ : `apps/front` (React + Tailwind + shadcn), `apps/back` (NestJS + LangChain) et `packages/shared` (types, schÃ©mas, helpers communs).

## Structure

```
.
â”œâ”€â”€ apps
â”‚   â”œâ”€â”€ back          # NestJS + LangChain + intÃ©grations mÃ©tÃ©o/destinations
â”‚   â””â”€â”€ front         # Vite + React 18 + Tailwind + shadcn/ui
â”œâ”€â”€ packages
â”‚   â””â”€â”€ shared        # Interfaces, schÃ©mas zod, constantes
â”œâ”€â”€ infra             # Docker Compose et orchestration locale
â”œâ”€â”€ pnpm-workspace.yaml
â””â”€â”€ turbo.json
```

## Commandes clÃ©s

| Action | Commande |
| ------ | -------- |
| Installer les deps | `make install` |
| Lancer front | `make dev-front` |
| Lancer back | `make dev-back` |
| Lancer tous les dev servers | `make dev` (Turbo) |
| Build complet | `make build` |

> ðŸ’¡ Ajoutez `USE_DOCKER=1` Ã  nâ€™importe quelle cible `make` pour tout exÃ©cuter dans le conteneur `toolbox` (ex. `USE_DOCKER=1 make dev`). Cela Ã©vite dâ€™installer Node.js ou pnpm en local.

## Backend (NestJS)

- Endpoint principalÂ : `POST /conversation/query`
- Corps attenduÂ :

```jsonc
{
  "question": "week-end nature <500â‚¬",
  "conversationId": "optionnel",
  "preferences": [{ "key": "budget", "value": "moins-500" }],
  "location": { "latitude": 48.8566, "longitude": 2.3522 }
}
```

- RÃ©ponseÂ : `DestinationQueryResponse` (conversation + cartes tapÃ©es dans `@3xod/shared`).
- ModulesÂ : mÃ©tÃ©o (Open-Meteo), destinations (API externe ou fallback), LangChain (classement LLM + heuristiques) et conversation (mÃ©moire en mÃ©moire + orchestration).

## Frontend (React + Tailwind)

- Vite + React 18 + Suspense + lazy loading des grilles de cartes.
- UI mobile-first (shadcn/ui + Tailwind). Les prÃ©fÃ©rences sont gÃ©rÃ©es avec Redux Toolkit, tandis que les appels conversationnels utilisent React Query.
- Variables dâ€™environnementÂ : `VITE_API_URL` (pointe par dÃ©faut sur `http://localhost:4000`).

## Docker

- `apps/back/Dockerfile`Â : build multi-Ã©tapes Node 20 + pnpm.
- `apps/front/Dockerfile`Â : build Vite, runtime nginx.
- `infra/docker-compose.yml` lance front, back, Redis (mÃ©moire future) et Qdrant (vector store LangChain). Il expose aussi `toolbox`, un conteneur Node 20 + pnpm montÃ© sur le dÃ©pÃ´t qui sert dâ€™environnement de dev.

### Mode full Docker (sans Node/pnpm local)

1. Construire lâ€™image dev (une seule fois)Â :  
   `docker compose -f infra/docker-compose.yml build toolbox`
2. Installer les dÃ©pendances via DockerÂ :  
   `USE_DOCKER=1 make install`
3. Lancer les serveurs front/back avec hot reload (ports 5173 et 4000 exposÃ©s)Â :  
   `USE_DOCKER=1 make dev`
4. ExÃ©cuter ponctuellement lint/tests/CLIÂ :  
   `docker compose -f infra/docker-compose.yml run --rm toolbox pnpm lint`
5. Monter les services annexes (Redis + Qdrant) ou des builds prodÂ :  
   `docker compose -f infra/docker-compose.yml up redis vectorstore`  
   `docker compose -f infra/docker-compose.yml up --build front back`

## Variables dâ€™environnement

Consulter `.env.example`. Copier vers `.env` (ou `apps/back/.env`) puis complÃ©ter les clÃ©s API (OpenAI, fournisseur destinations).

## Prochaines Ã©tapes

1. Connecter une base persistante (Postgres ou Supabase) pour sauvegarder les conversations.
2. IntÃ©grer rÃ©ellement un provider destinations (Foursquare, Amadeus, etc.) et complÃ©ter les payloads.
3. Ajouter les cartes Â« restos Â» et autres verticales puis brancher un moteur de scoring plus fin (LangChain Tools + vector store).
4. Couvrir le pipeline avec des tests E2E (Playwright cÃ´tÃ© front + Pact ou Supertest cÃ´tÃ© API).
